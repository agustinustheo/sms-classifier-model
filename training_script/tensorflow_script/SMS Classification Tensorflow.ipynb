{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from nltk.tokenize import PunktSentenceTokenizer, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indonesian SMS Preprocessing\n",
    "def convertTackyText(text):\n",
    "    words = word_tokenize(text)\n",
    "    new_string = ''\n",
    "    for msg in words:\n",
    "        new_word = ''\n",
    "        alpha_flag = False\n",
    "        digit_flag = False\n",
    "        for c in msg:\n",
    "            if c.isalpha():\n",
    "                alpha_flag = True\n",
    "            elif c.isdigit():\n",
    "                digit_flag = True\n",
    "        \n",
    "        if alpha_flag and digit_flag:\n",
    "            msg = msg.lower()\n",
    "            if msg[-4:] != 'ribu' and msg[-3:] != 'rbu' and msg[-2:] != 'rb':\n",
    "                for c in msg:\n",
    "                    if c == '1':\n",
    "                        c = 'i'\n",
    "                    elif c == '2':\n",
    "                        c = 's'\n",
    "                    elif c == '3':\n",
    "                        c = 'e'\n",
    "                    elif c == '4':\n",
    "                        c = 'a'\n",
    "                    elif c == '5':\n",
    "                        c = 's'\n",
    "                    elif c == '6':\n",
    "                        c = 'g'\n",
    "                    elif c == '7':\n",
    "                        c = 't'\n",
    "                    elif c == '8':\n",
    "                        c = 'b'\n",
    "                    elif c == '9':\n",
    "                        c = 'g'\n",
    "                    elif c == '0':\n",
    "                        c = 'o'\n",
    "                    new_word = new_word + c\n",
    "        \n",
    "        if new_word != '':\n",
    "            new_string = new_string + new_word + ' '\n",
    "        else:\n",
    "            new_string = new_string + msg + ' '\n",
    "\n",
    "    return new_string\n",
    "\n",
    "def preproccess_text(text_messages):\n",
    "    # change words to lower case\n",
    "    processed = text_messages.lower()\n",
    "\n",
    "    # Replace email addresses with 'emailaddress'\n",
    "    processed = re.sub(r'^.+@[^\\.].*\\.[a-z]{2,}$', ' emailaddress ', processed)\n",
    "        \n",
    "    # Replace phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = re.sub(r'(\\()?(\\+62|62|0)(\\d{2,3})?\\)?[ .-]?\\d{2,4}[ .-]?\\d{2,4}[ .-]?\\d{2,4}', ' phonenumber ', processed)\n",
    "\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = re.sub(r'[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)', ' webaddress ', processed)\n",
    "    processed = processed.replace('http', '')\n",
    "    processed = processed.replace('https', '')\n",
    "    \n",
    "    # Replace money symbols with 'moneysymbol' (£ can by typed with ALT key + 156)\n",
    "    processed = re.sub(r'£|\\$', 'moneysymbol ', processed)\n",
    "    processed = processed.replace(' rp.', ' moneysymbol ')\n",
    "    processed = processed.replace(' rp', ' moneysymbol ')\n",
    "        \n",
    "    # Replace numbers with 'number'\n",
    "    processed = re.sub(r'\\d+(\\.\\d+)?', ' number ', processed)\n",
    "\n",
    "    # Remove punctuation\n",
    "    processed = re.sub(r'[.,\\/#!%\\^&\\*;:+{}=\\-_`~()?]', ' ', processed)\n",
    "\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = re.sub(r'\\s+', ' ', processed)\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = re.sub(r'^\\s+|\\s+?$', '', processed)\n",
    "    return processed\n",
    "\n",
    "def preproccess_df(text_messages):\n",
    "    # change words to lower case\n",
    "    processed = text_messages.str.lower()\n",
    "\n",
    "    # Replace email addresses with 'emailaddress'\n",
    "    processed = processed.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', ' emailaddress ')\n",
    "        \n",
    "    # Replace phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = processed.str.replace(r'(\\()?(\\+62|62|0)(\\d{2,3})?\\)?[ .-]?\\d{2,4}[ .-]?\\d{2,4}[ .-]?\\d{2,4}', ' phonenumber' )\n",
    "\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = processed.str.replace(r'[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)', ' webaddress ')\n",
    "    processed = processed.str.replace('http', '')\n",
    "    processed = processed.str.replace('https', '')\n",
    "    \n",
    "    # Replace money symbols with 'moneysymbol' (£ can by typed with ALT key + 156)\n",
    "    processed = processed.str.replace(r'£|\\$', ' moneysymbol ')\n",
    "    processed = processed.str.replace(' rp.', ' moneysymbol ')\n",
    "    processed = processed.str.replace(' rp', ' moneysymbol ')\n",
    "        \n",
    "    # Replace numbers with 'number'\n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', ' number ')\n",
    "\n",
    "    # Remove punctuation\n",
    "    processed = processed.str.replace(r'[.,\\/#!%\\^&\\*;:{}=\\-_`~()?]', ' ')\n",
    "\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features_f = open(\"word_features.pickle\", \"rb\")\n",
    "word_features = pickle.load(word_features_f)\n",
    "word_features_f.close()\n",
    "print(\"Created bag of word features!\")\n",
    "\n",
    "ordenc = OrdinalEncoder()\n",
    "encoded_word_features = encoder.fit_transform(word_features)\n",
    "for i in range(0, len(encoded_word_features)):\n",
    "    encoded_word_features[i]+=4\n",
    "\n",
    "# Filler Grammar to mark Start of a sentence and to add empty fillers to make equal shapes of data\n",
    "word_features.append(\"<PAD>\")\n",
    "word_features.append(\"<START>\")\n",
    "word_features.append(\"<UNK>\")\n",
    "word_features.append(\"<UNUSED>\")\n",
    "\n",
    "encoded_word_features=np.append(encoded_word_features, [0,1,2,3])\n",
    "\n",
    "print(word_features)\n",
    "print(encoded_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = []\n",
    "    features.append(1)\n",
    "    for idx, word in enumerate(word_features):\n",
    "        if word in words:\n",
    "            features.append(encoded_word_features[idx])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "\n",
    "print(\"Reading data...\")\n",
    "df = pd.read_csv('corpus/sms_corpus/data.txt', engine='python', sep=\"<%>\", header=None)\n",
    "print(\"Data loaded\")\n",
    "\n",
    "classes = df[[0]]\n",
    "sms_data = preproccess_df(df[1])\n",
    "\n",
    "oneenc = OneHotEncoder(sparse=False)\n",
    "Y = oneenc.fit_transform(classes)\n",
    "\n",
    "# Now lets do it for all the messages\n",
    "messages = list(zip(sms_data, Y))\n",
    "\n",
    "# Call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]\n",
    "\n",
    "preferred_range=25\n",
    "for x in featuresets:\n",
    "    arr_length=len(x[0])\n",
    "    if arr_length < preferred_range:\n",
    "        for i in range(arr_length, preferred_range):\n",
    "            x[0].append(0)\n",
    "    elif arr_length > preferred_range:\n",
    "        diff=arr_length-preferred_range\n",
    "        for i in range(0, diff):\n",
    "            del x[0][i]\n",
    "\n",
    "x_data, y_data = zip(*featuresets)\n",
    "train_input, test_input, train_output, test_output = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "train_input=np.array(train_input)\n",
    "test_input=np.array(test_input)\n",
    "train_output=np.array(train_output)\n",
    "test_output=np.array(test_output)\n",
    "\n",
    "print(test_input)\n",
    "print(train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=2000\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_input,\n",
    "                   train_output,\n",
    "                   epochs=40,\n",
    "                   batch_size=50,\n",
    "                   validation_data=(test_input, test_output),\n",
    "                   verbose=1)\n",
    "model.save('sms_classifier_tf_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
