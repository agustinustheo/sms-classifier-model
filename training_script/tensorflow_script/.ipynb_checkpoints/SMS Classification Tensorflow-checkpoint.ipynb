{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from nltk.tokenize import PunktSentenceTokenizer, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indonesian SMS Preprocessing\n",
    "def convertTackyText(text):\n",
    "    words = word_tokenize(text)\n",
    "    new_string = ''\n",
    "    for msg in words:\n",
    "        new_word = ''\n",
    "        alpha_flag = False\n",
    "        digit_flag = False\n",
    "        for c in msg:\n",
    "            if c.isalpha():\n",
    "                alpha_flag = True\n",
    "            elif c.isdigit():\n",
    "                digit_flag = True\n",
    "        \n",
    "        if alpha_flag and digit_flag:\n",
    "            msg = msg.lower()\n",
    "            if msg[-4:] != 'ribu' and msg[-3:] != 'rbu' and msg[-2:] != 'rb':\n",
    "                for c in msg:\n",
    "                    if c == '1':\n",
    "                        c = 'i'\n",
    "                    elif c == '2':\n",
    "                        c = 's'\n",
    "                    elif c == '3':\n",
    "                        c = 'e'\n",
    "                    elif c == '4':\n",
    "                        c = 'a'\n",
    "                    elif c == '5':\n",
    "                        c = 's'\n",
    "                    elif c == '6':\n",
    "                        c = 'g'\n",
    "                    elif c == '7':\n",
    "                        c = 't'\n",
    "                    elif c == '8':\n",
    "                        c = 'b'\n",
    "                    elif c == '9':\n",
    "                        c = 'g'\n",
    "                    elif c == '0':\n",
    "                        c = 'o'\n",
    "                    new_word = new_word + c\n",
    "        \n",
    "        if new_word != '':\n",
    "            new_string = new_string + new_word + ' '\n",
    "        else:\n",
    "            new_string = new_string + msg + ' '\n",
    "\n",
    "    return new_string\n",
    "\n",
    "def preproccess_text(text_messages):\n",
    "    # change words to lower case\n",
    "    processed = text_messages.lower()\n",
    "\n",
    "    # Replace email addresses with 'emailaddress'\n",
    "    processed = re.sub(r'^.+@[^\\.].*\\.[a-z]{2,}$', ' emailaddress ', processed)\n",
    "        \n",
    "    # Replace phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = re.sub(r'(\\()?(\\+62|62|0)(\\d{2,3})?\\)?[ .-]?\\d{2,4}[ .-]?\\d{2,4}[ .-]?\\d{2,4}', ' phonenumber ', processed)\n",
    "\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = re.sub(r'[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)', ' webaddress ', processed)\n",
    "    processed = processed.replace('http', '')\n",
    "    processed = processed.replace('https', '')\n",
    "    \n",
    "    # Replace money symbols with 'moneysymbol' (£ can by typed with ALT key + 156)\n",
    "    processed = re.sub(r'£|\\$', 'moneysymbol ', processed)\n",
    "    processed = processed.replace(' rp.', ' moneysymbol ')\n",
    "    processed = processed.replace(' rp', ' moneysymbol ')\n",
    "        \n",
    "    # Replace numbers with 'number'\n",
    "    processed = re.sub(r'\\d+(\\.\\d+)?', ' number ', processed)\n",
    "\n",
    "    # Remove punctuation\n",
    "    processed = re.sub(r'[.,\\/#!%\\^&\\*;:+{}=\\-_`~()?]', ' ', processed)\n",
    "\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = re.sub(r'\\s+', ' ', processed)\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = re.sub(r'^\\s+|\\s+?$', '', processed)\n",
    "    return processed\n",
    "\n",
    "def preproccess_df(text_messages):\n",
    "    # change words to lower case\n",
    "    processed = text_messages.str.lower()\n",
    "\n",
    "    # Replace email addresses with 'emailaddress'\n",
    "    processed = processed.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', ' emailaddress ')\n",
    "        \n",
    "    # Replace phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = processed.str.replace(r'(\\()?(\\+62|62|0)(\\d{2,3})?\\)?[ .-]?\\d{2,4}[ .-]?\\d{2,4}[ .-]?\\d{2,4}', ' phonenumber' )\n",
    "\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = processed.str.replace(r'[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)', ' webaddress ')\n",
    "    processed = processed.str.replace('http', '')\n",
    "    processed = processed.str.replace('https', '')\n",
    "    \n",
    "    # Replace money symbols with 'moneysymbol' (£ can by typed with ALT key + 156)\n",
    "    processed = processed.str.replace(r'£|\\$', ' moneysymbol ')\n",
    "    processed = processed.str.replace(' rp.', ' moneysymbol ')\n",
    "    processed = processed.str.replace(' rp', ' moneysymbol ')\n",
    "        \n",
    "    # Replace numbers with 'number'\n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', ' number ')\n",
    "\n",
    "    # Remove punctuation\n",
    "    processed = processed.str.replace(r'[.,\\/#!%\\^&\\*;:{}=\\-_`~()?]', ' ')\n",
    "\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bag of word features!\n"
     ]
    }
   ],
   "source": [
    "word_features_f = open(\"word_features.pickle\", \"rb\")\n",
    "word_features = pickle.load(word_features_f)\n",
    "word_features_f.close()\n",
    "print(\"Created bag of word features!\")\n",
    "\n",
    "ordenc = OrdinalEncoder()\n",
    "encoded_word_features = encoder.fit_transform(word_features)\n",
    "for i in range(0, len(encoded_word_features)):\n",
    "    encoded_word_features[i]+=4\n",
    "\n",
    "# Filler Grammar to mark Start of a sentence and to add empty fillers to make equal shapes of data\n",
    "word_features.append(\"<PAD>\")\n",
    "word_features.append(\"<START>\")\n",
    "word_features.append(\"<UNK>\")\n",
    "word_features.append(\"<UNUSED>\")\n",
    "\n",
    "encoded_word_features=np.append(encoded_word_features, [0,1,2,3])\n",
    "\n",
    "print(word_features)\n",
    "print(encoded_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = []\n",
    "    features.append(1)\n",
    "    for idx, word in enumerate(word_features):\n",
    "        if word in words:\n",
    "            features.append(encoded_word_features[idx])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Data loaded\n",
      "[[   1   17  556 ...    0    0    0]\n",
      " [   1   17  333 ...    0    0    0]\n",
      " [   1  570 1494 ...    0    0    0]\n",
      " ...\n",
      " [ 333 1126  332 ...  417  960  230]\n",
      " [   1  333  687 ...    0    0    0]\n",
      " [   1  795  647 ...    0    0    0]]\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "\n",
    "print(\"Reading data...\")\n",
    "df = pd.read_csv('corpus/sms_corpus/data.txt', engine='python', sep=\"<%>\", header=None)\n",
    "print(\"Data loaded\")\n",
    "\n",
    "classes = df[[0]]\n",
    "sms_data = preproccess_df(df[1])\n",
    "\n",
    "oneenc = OneHotEncoder(sparse=False)\n",
    "Y = oneenc.fit_transform(classes)\n",
    "\n",
    "# Now lets do it for all the messages\n",
    "messages = list(zip(sms_data, Y))\n",
    "\n",
    "# Call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]\n",
    "\n",
    "preferred_range=25\n",
    "for x in featuresets:\n",
    "    arr_length=len(x[0])\n",
    "    if arr_length < preferred_range:\n",
    "        for i in range(arr_length, preferred_range):\n",
    "            x[0].append(0)\n",
    "    elif arr_length > preferred_range:\n",
    "        diff=arr_length-preferred_range\n",
    "        for i in range(0, diff):\n",
    "            del x[0][i]\n",
    "\n",
    "x_data, y_data = zip(*featuresets)\n",
    "train_input, test_input, train_output, test_output = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "train_input=np.array(train_input)\n",
    "test_input=np.array(test_input)\n",
    "train_output=np.array(train_output)\n",
    "test_output=np.array(test_output)\n",
    "\n",
    "print(test_input)\n",
    "print(train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, None, 16)          32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_32  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 32,323\n",
      "Trainable params: 32,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size=2000\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/40\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0302 - acc: 0.9883 - val_loss: 0.4805 - val_acc: 0.8467\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0301 - acc: 0.9850 - val_loss: 0.4812 - val_acc: 0.8467\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0297 - acc: 0.9867 - val_loss: 0.4827 - val_acc: 0.8467\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0293 - acc: 0.9850 - val_loss: 0.4846 - val_acc: 0.8467\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0289 - acc: 0.9850 - val_loss: 0.4872 - val_acc: 0.8467\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0603 - acc: 0.980 - 0s 47us/sample - loss: 0.0284 - acc: 0.9867 - val_loss: 0.4879 - val_acc: 0.8467\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0319 - acc: 0.980 - 0s 47us/sample - loss: 0.0284 - acc: 0.9850 - val_loss: 0.4898 - val_acc: 0.8467\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.0279 - acc: 0.9867 - val_loss: 0.4904 - val_acc: 0.8467\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0277 - acc: 0.9883 - val_loss: 0.4927 - val_acc: 0.8467\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.0271 - acc: 0.9883 - val_loss: 0.4946 - val_acc: 0.8467\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0270 - acc: 0.9867 - val_loss: 0.4973 - val_acc: 0.8467\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.0267 - acc: 0.9867 - val_loss: 0.4978 - val_acc: 0.8467\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0265 - acc: 0.9850 - val_loss: 0.4982 - val_acc: 0.8467\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0263 - acc: 0.9867 - val_loss: 0.4997 - val_acc: 0.8467\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0263 - acc: 0.9883 - val_loss: 0.5036 - val_acc: 0.8467\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0257 - acc: 0.9883 - val_loss: 0.5045 - val_acc: 0.8467\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0256 - acc: 0.9883 - val_loss: 0.5054 - val_acc: 0.8467\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0255 - acc: 0.9883 - val_loss: 0.5079 - val_acc: 0.8467\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0251 - acc: 0.9867 - val_loss: 0.5084 - val_acc: 0.8467\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0250 - acc: 0.9867 - val_loss: 0.5092 - val_acc: 0.8467\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0247 - acc: 0.9867 - val_loss: 0.5109 - val_acc: 0.8467\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.0246 - acc: 0.9867 - val_loss: 0.5128 - val_acc: 0.8467\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0243 - acc: 0.9883 - val_loss: 0.5131 - val_acc: 0.8467\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0242 - acc: 0.9850 - val_loss: 0.5149 - val_acc: 0.8467\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0241 - acc: 0.9867 - val_loss: 0.5168 - val_acc: 0.8467\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.0240 - acc: 0.9833 - val_loss: 0.5197 - val_acc: 0.8467\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0237 - acc: 0.9883 - val_loss: 0.5202 - val_acc: 0.8467\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0236 - acc: 0.9833 - val_loss: 0.5210 - val_acc: 0.8467\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.0235 - acc: 0.9850 - val_loss: 0.5224 - val_acc: 0.8467\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0233 - acc: 0.9867 - val_loss: 0.5235 - val_acc: 0.8467\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0230 - acc: 0.9867 - val_loss: 0.5250 - val_acc: 0.8467\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0229 - acc: 0.9900 - val_loss: 0.5266 - val_acc: 0.8467\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0229 - acc: 0.9850 - val_loss: 0.5287 - val_acc: 0.8467\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0231 - acc: 0.9900 - val_loss: 0.5304 - val_acc: 0.8467\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.0228 - acc: 0.9867 - val_loss: 0.5298 - val_acc: 0.8467\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0225 - acc: 0.9883 - val_loss: 0.5318 - val_acc: 0.8467\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.0228 - acc: 0.9850 - val_loss: 0.5347 - val_acc: 0.8467\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0224 - acc: 0.9867 - val_loss: 0.5353 - val_acc: 0.8467\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0225 - acc: 0.9883 - val_loss: 0.5344 - val_acc: 0.8467\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0221 - acc: 0.9883 - val_loss: 0.5368 - val_acc: 0.8467\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input,\n",
    "                   train_output,\n",
    "                   epochs=40,\n",
    "                   batch_size=50,\n",
    "                   validation_data=(test_input, test_output),\n",
    "                   verbose=1)\n",
    "model.save('sms_classifier_tf_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
